# filename: fetch_sohu_news.py
#generated by gpt4, it works!

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options

# Setup Chrome options
chrome_options = Options()
chrome_options.add_argument("--headless")  # Ensure GUI is off
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# Path to Chrome and ChromeDriver
chrome_path = "/home/lxh/dev/withautogen/chrome-linux64/chrome"
chromedriver_path = "/home/lxh/dev/withautogen/chromedriver-linux64/chromedriver"
chrome_options.binary_location = chrome_path

# Set service with ChromeDriver
service = Service(executable_path=chromedriver_path)

# Set up driver
driver = webdriver.Chrome(service=service, options=chrome_options)

# Target URL
url = "http://sohu.com"

# Navigate to the URL
driver.get(url)

try:
    # Assuming news items can be found in these elements (update as needed)
    news_items = driver.find_elements(By.CSS_SELECTOR, "a")

    # Print out the first few news titles and URLs
    for item in news_items[:10]:  # Adjust the slice as needed
        title = item.text.strip()
        link = item.get_attribute('href')
        if title and link:
            print(f"Title: {title}\nLink: {link}\n")
finally:
    # Close the driver
    driver.quit()